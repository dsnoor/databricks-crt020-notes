{"cells":[{"cell_type":"markdown","source":["# Create a DataFrame/Dataset\n\nThis notebook covers the Spark Session topics about creating Dataframes, just to refresh:\n\nCandidates are expected to know how to:\n\n* Create a DataFrame/Dataset from a collection (e.g. list or set)\n* Create a DataFrame for a range of numbers"],"metadata":{}},{"cell_type":"markdown","source":["## Creating Dataframes\n\nSpark Session has a method called [createDataFrame](https://spark.apache.org/docs/2.1.0/api/python/pyspark.sql.html#pyspark.sql.SparkSession.createDataFrame), which receive data and convert it to a dataframe. This method params are listed below:\n\n<br>\n`SparkSession.createDataFrame(data, schema=None, samplingRatio=None, verifySchema=True)` \n\n<br>\n\n* `data`: Data that will populate a Dataframe, you can pass a python list, a pandas dataframe a numpy array or fuck it\n* `schema(optional)`: Data types for the Dataframe, if you don't input any schema, spark will try to infer the schema from `data`\n* `samplingRatio(optional)`: Control the amount of data used on schema infering, may be good to use with big Datasets\n* `verifySchema(optional)`: Validate the input schema for the entire Dataframe"],"metadata":{}},{"cell_type":"markdown","source":["## Creating a dataframe from a python list\n\nOkay, let's create a spark dataframe from a single list\n\nWhen creating a dataframe from a list, you need to have a nested list structure to have rows, a single list will represent a single row on a Dataframe, unless you pass a schema for the list, then Databricks will consider the list as a one column dataframe"],"metadata":{}},{"cell_type":"code","source":["#creating a spark dataframe from a python list\n\nmy_list = [1,2,3,4,5,6,7,8]\ntry:\n  my_df = spark.createDataFrame(my_list)\nexcept:\n  print('cant infer schema from a single row')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">cant infer schema from a single row\n</div>"]}}],"execution_count":4},{"cell_type":"markdown","source":["Oops, we didn't passed the schema for the list data, and **Spark can't infer a schema from a single row**, so let's pass a schema to the `createDataFrame` method"],"metadata":{}},{"cell_type":"code","source":["import pyspark.sql.types as tp\nsingle_col_df = spark.createDataFrame(my_list,schema=tp.IntegerType())\n\ndisplay(single_col_df.limit(2))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>value</th></tr></thead><tbody><tr><td>1</td></tr><tr><td>2</td></tr></tbody></table></div>"]}}],"execution_count":6},{"cell_type":"markdown","source":["Yaaaay, we just created our **first Dataframe!**\n\n\nYou can create a multi-column dataframe with lists as well, just create a nested list structure and go for it"],"metadata":{}},{"cell_type":"code","source":["nested_list = [[1,'nothing'],[2,'happens'],[3,'feijoada']]\n\nnested_list_df = spark.createDataFrame(nested_list)\n\ndisplay(nested_list_df)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>_1</th><th>_2</th></tr></thead><tbody><tr><td>1</td><td>nothing</td></tr><tr><td>2</td><td>happens</td></tr><tr><td>3</td><td>feijoada</td></tr></tbody></table></div>"]}}],"execution_count":8},{"cell_type":"markdown","source":["Notice that no schema has been passed on the `createDataFrame` method, but Databricks still created the right data types for the dataframe, that's because Spark can **infer the schema from the input data**\n\nBut even with infer schema, column names got pretty ugly heh? Let's fix this."],"metadata":{}},{"cell_type":"code","source":["#it's possible to inform column names on the schema parameter, passing column names as a list to the method\n\nnested_list_df_with_names = spark.createDataFrame(nested_list,schema=['order','reality'])\n\ndisplay(nested_list_df_with_names)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>order</th><th>reality</th></tr></thead><tbody><tr><td>1</td><td>nothing</td></tr><tr><td>2</td><td>happens</td></tr><tr><td>3</td><td>feijoada</td></tr></tbody></table></div>"]}}],"execution_count":10},{"cell_type":"markdown","source":["If Spark aren't infering your schema correctly, you can specify the entire schema, just like this example bellow."],"metadata":{}},{"cell_type":"code","source":["input_schema = tp.StructType([tp.StructField('order',tp.IntegerType()),\n                              tp.StructField('reality',tp.StringType())\n                             ])\n\nnested_list_df_with_strict_schema = spark.createDataFrame(nested_list,schema=input_schema)\n\ndisplay(nested_list_df_with_strict_schema)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>order</th><th>reality</th></tr></thead><tbody><tr><td>1</td><td>nothing</td></tr><tr><td>2</td><td>happens</td></tr><tr><td>3</td><td>feijoada</td></tr></tbody></table></div>"]}}],"execution_count":12},{"cell_type":"markdown","source":["If you compare `nested_list_df_with_names` and `nested_list_df_with_strict_schema` you'll see that they have different schemas, because Spark inferred `LongType` for the first column of the list, and in the second one i specified the schema, so no inferring occured."],"metadata":{}},{"cell_type":"markdown","source":["## Creating a dataframe from pandas\nNow that we have lists covered up, the same techniques apply to **pandas Series and pandas Dataframes**. Let's give it a try:"],"metadata":{}},{"cell_type":"code","source":["import numpy as np\nimport pandas as pd\n\npandas_dataframe = pd.DataFrame(np.column_stack((np.arange(0,300),np.random.rand(300))),columns=['this_is_spartaaa','power_level'])\n\nspark_df_from_pandas_dataframe = spark.createDataFrame(pandas_dataframe)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":15},{"cell_type":"markdown","source":["Spark grab the column names from pandas, which is very nice when working with both.\n\n**Extra:** Spark Dataframes can be converted back to pandas dataframes, using `toPandas()` method."],"metadata":{}},{"cell_type":"code","source":["pandas_dataframe_from_spark = spark_df_from_pandas_dataframe.toPandas()\n\npandas_dataframe_from_spark.head()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<div style=\"max-width:1500px;overflow:auto;\">\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>this_is_spartaaa</th>\n      <th>power_level</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.632697</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>0.132692</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2.0</td>\n      <td>0.253096</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3.0</td>\n      <td>0.655194</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4.0</td>\n      <td>0.558909</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":17},{"cell_type":"markdown","source":["## Create a DataFrame for a range of numbers\n\nSpark has his own ways to generate Dataframes, so you can do it all inside Spark.\n\n[spark.range(start,end,increment,num_partitions)](https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.SparkContext.range) create a single column dataframe from a range of integers"],"metadata":{}},{"cell_type":"code","source":["generated_dataframe = spark.range(0,10,1,2)\n\ndisplay(generated_dataframe.limit(3))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>id</th></tr></thead><tbody><tr><td>0</td></tr><tr><td>1</td></tr><tr><td>2</td></tr></tbody></table></div>"]}}],"execution_count":19},{"cell_type":"code","source":["#you can create a random number column as well\nimport pyspark.sql.functions as F\nrandom_generated_dataframe = generated_dataframe.withColumn('meaning_of_life',F.rand(42))\n\ndisplay(random_generated_dataframe.limit(3))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>id</th><th>meaning_of_life</th></tr></thead><tbody><tr><td>0</td><td>0.6661236774413726</td></tr><tr><td>1</td><td>0.8583151351252906</td></tr><tr><td>2</td><td>0.9139963682495181</td></tr></tbody></table></div>"]}}],"execution_count":20},{"cell_type":"markdown","source":["## Artisan made Spark Dataframe\n\nIf any of the above methods didn't solved your problem, you can specify you dataframe totally manually, row by row. Check this out:"],"metadata":{}},{"cell_type":"code","source":["#generate a manual Dataframe from rows\n\nfrom pyspark.sql import Row\n\nrow = [Row(name='Lone', surname='Wolf')]\nsingle_row_dataframe = spark.createDataFrame(row)\n\ndisplay(single_row_dataframe)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>name</th><th>surname</th></tr></thead><tbody><tr><td>Lone</td><td>Wolf</td></tr></tbody></table></div>"]}}],"execution_count":22},{"cell_type":"markdown","source":["##Conclusion\n\nNow you know how to generate Dataframes from **typed data**, this is useful when you need to complement data with discrete domain, or infuse small data into another Dataframes.\n\nIf you know any other way to generate a Spark Dataframe which is not denoted above, feel free to create a PR or contact me."],"metadata":{}}],"metadata":{"name":"creating_dataframes","notebookId":3364551252242351},"nbformat":4,"nbformat_minor":0}
